{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q diffusers"
      ],
      "metadata": {
        "id": "4kT7uiBEQyT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# College project"
      ],
      "metadata": {
        "id": "Ux1WRqqAKMnJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade -q gradio"
      ],
      "metadata": {
        "id": "w84PEBksFNJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q accelerate"
      ],
      "metadata": {
        "id": "L5825woXkHZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from diffusers import StableDiffusionControlNetImg2ImgPipeline, ControlNetModel, UniPCMultistepScheduler\n",
        "from diffusers.utils import load_image\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import cv2\n",
        "from PIL import Image\n"
      ],
      "metadata": {
        "id": "N4WJF2lD3JPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import PIL"
      ],
      "metadata": {
        "id": "HRmie2KTMhcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "image = PIL.Image.open('/content/ip1.png')\n"
      ],
      "metadata": {
        "id": "ZJO9_tAqXTty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "image = load_image(\n",
        "    \"/content/ip1.png\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "bQVOeJYepVgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#input image of dimension 512 x 512 , format .png\n",
        "image"
      ],
      "metadata": {
        "id": "zYeXYkADU4yV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# load control net and stable diffusion v1-5\n",
        "controlnet = ControlNetModel.from_pretrained(\"lllyasviel/sd-controlnet-canny\", torch_dtype=torch.float16)\n",
        "pipe = StableDiffusionControlNetImg2ImgPipeline.from_pretrained(\n",
        "    \"runwayml/stable-diffusion-v1-5\", controlnet=controlnet, torch_dtype=torch.float16,\n",
        "     safety_checker = None,\n",
        "    requires_safety_checker = False\n",
        ")"
      ],
      "metadata": {
        "id": "KRT5dkHHKRne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# speed up diffusion process with faster scheduler and memory optimization\n",
        "\n",
        "pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "pipe.enable_model_cpu_offload()\n",
        "\n"
      ],
      "metadata": {
        "id": "ERK_OT1_loiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_control_image(image):\n",
        "  np_image = np.array(image)\n",
        "  # get canny image\n",
        "  np_image = cv2.Canny(np_image, 100, 200)\n",
        "  np_image = np_image[:, :, None]\n",
        "  np_image = np.concatenate([np_image, np_image, np_image], axis=2)\n",
        "  canny_image = PIL.Image.fromarray(np_image)\n",
        "  return canny_image\n",
        "#canny_image = get_control_image(image)"
      ],
      "metadata": {
        "id": "tIhsAyekvI-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "#pipe.enable_model_cpu_offload()\n",
        "def generate(ip_image,control_image,prompt):\n",
        "  generator = torch.manual_seed(0)\n",
        "  image = pipe(\n",
        "      prompt=prompt,\n",
        "      num_inference_steps=30,\n",
        "      generator=generator,\n",
        "      image=ip_image,\n",
        "      control_image=control_image,\n",
        "  ).images[0]\n",
        "  return image\n",
        "#generate(image,canny_image,\"an abstract art of japanese women\")"
      ],
      "metadata": {
        "id": "F0AjlvnVl0lB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: save the generated image\n",
        "image.save(\"gen_girl.jpg\")\n"
      ],
      "metadata": {
        "id": "tRHnrE5El2yH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# image generation function\n",
        "def image_to_image(input_png_image, prompt):\n",
        "  image = PIL.Image.fromarray(input_png_image)\n",
        "  image = load_image(image)\n",
        "  control_image = get_control_image(image)\n",
        "  generated_image = generate(image,control_image,prompt)\n",
        "  return generated_image"
      ],
      "metadata": {
        "id": "W_j9kqJrmMN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img  =  image_to_image(\"/content/ip1.png\",'a hyper realistic indian women')"
      ],
      "metadata": {
        "id": "xY7okzV4nS9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img"
      ],
      "metadata": {
        "id": "_SX3W2iQBE4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "from gradio import Image, Textbox\n",
        "from gradio import Image\n",
        "\n",
        "\n",
        "interface = gr.Interface(\n",
        "    fn = image_to_image,\n",
        "    inputs=[Image(label=\"Input Image\"), Textbox(label=\"Text Prompt\")],\n",
        "    outputs=Image(label=\"Generated Image\"),\n",
        "    title=\"Text-Driven Visual Translation: Sketch-to-Photo Guided Synthesis\",\n",
        "    description=\"Use pretrained Stable Diffusion model so as to perform Text-Driven Image Synthesis.\",\n",
        "   elem_id=\"my-image-to-image-app\",\n",
        ")\n",
        "\n",
        "# Launch the Gradio interface in the notebook\n",
        "interface.launch(share=True,debug=True)\n"
      ],
      "metadata": {
        "id": "8dFW63qQFGfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gradio app.py"
      ],
      "metadata": {
        "id": "gH591C0bS8jC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PIL"
      ],
      "metadata": {
        "id": "xWd8eOi3WFBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gradio deploy"
      ],
      "metadata": {
        "id": "q7ticjvXO3XU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "0"
      ],
      "metadata": {
        "id": "jv801ZBeN3rP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}